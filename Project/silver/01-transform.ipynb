{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5656e69c-0229-435c-9d7f-2c41c5554334",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This notebook is used to read data from bronze tables, transform it, and then populate the silver tables  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b65fa4b0-6576-4518-8faa-77dfdd3f8cdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Transformations: \n",
    "- Make sure dimension tables dont have duplicates, only store recent data \n",
    "- Make sure there aren't any null values for High priority columns \n",
    "\n",
    "Fact Tables: Make sure they dont have nulls, duplicates MIGHT not be an issue  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb41b838-9cd1-4a2c-bbde-1c383f4a7342",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "* Only transforming the new data ingested in bronze, Using loaded_ts col for that because COPY INTO does not support DELTA format (Bz layer data is in delta format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "667c1441-03bd-476a-876f-b3c169f5b208",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class silver():\n",
    "    def __init__(self):\n",
    "        self.silver_home = 'abfss://silver@datalakeselectivaproject.dfs.core.windows.net/edw'\n",
    "        self.bronze_home = 'abfss://bronze@datalakeselectivaproject.dfs.core.windows.net/'\n",
    "\n",
    "        self.expectedDims = ['channels/', 'customers/', 'products/', 'promotions/', \n",
    "                             'supplementary_demographics/', 'times/']\n",
    "        self.expectedFacts = ['costs/', 'sales/']\n",
    "        self.pk_dict = {'channels':'channel_id', \n",
    "           'costs': 'PROD_ID, CHANNEL_ID, TIME_ID, PROMO_ID', \n",
    "           'customers': 'CUST_ID', \n",
    "           'products': 'product_id', \n",
    "           'promotions': 'PROMO_ID', \n",
    "           'times': 'TIME_ID',\n",
    "           'sales': 'PROD_ID, CUST_ID, TIME_ID, CHANNEL_ID, PROMO_ID',\n",
    "           'supplementary_demographics': 'CUST_ID'\n",
    "           }\n",
    "\n",
    "    def get_table_list(self, layer):\n",
    "        if layer == 'silver':\n",
    "            tableList = [t.name for t in dbutils.fs.ls(self.silver_home)]\n",
    "            return tableList\n",
    "        elif layer == 'bronze':\n",
    "            tableList = [t.name for t in dbutils.fs.ls(self.bronze_home)]\n",
    "            return tableList\n",
    "        else:\n",
    "            print(f'Invalid layer! cant get Table List for layer {layer}')\n",
    "\n",
    "    ############################\n",
    "    def get_recent_ts(self, table):\n",
    "        from pyspark.sql.functions import max\n",
    "        tgtTable = '`selectiva-project`.edw.' + table[:len(table) - 1] + '_edw'\n",
    "        print(f\"\\tGetting most recent loaded_ts for: {tgtTable}\")\n",
    "\n",
    "        if spark._jsparkSession.catalog().tableExists(f\"{tgtTable}\"):\n",
    "            df = spark.read.format('delta').option('header', 'true').table(tgtTable)\n",
    "            if df.count() > 0:\n",
    "                return (df.agg(max(\"loaded_ts\")).collect()[0][0])\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_bz_table(self, table):\n",
    "        bzTablePath = self.bronze_home + table \n",
    "        print(f\"\\tLoading Bronze Table at: {bzTablePath}\")\n",
    "        return (spark.read.format('delta').option('header', 'true').load(bzTablePath)\n",
    "        )\n",
    "    \n",
    "    # only take the most recent data in bronzeDf based on the loaded_ts\n",
    "    def filter_bz_table(self, bzDf, ts):\n",
    "        from pyspark.sql.functions import col\n",
    "        if ts is not None:\n",
    "            print(f\"\\tFiltering Bronze Data on loaded_ts\")\n",
    "            return (bzDf.filter(col(\"loaded_ts\") > ts))\n",
    "        else:\n",
    "            print(\"\\tMost recent ts is Null\")\n",
    "            return bzDf\n",
    "    \n",
    "    # drop duplicates and null Primary key cols from the dataframe\n",
    "    def clean_df(self, df, table):\n",
    "        table_name = table[:len(table) - 1]\n",
    "        pk_cols = self.pk_dict[table_name]\n",
    "        if isinstance(pk_cols, str):\n",
    "            pk_cols = [col.strip() for col in pk_cols.split(\",\")] \n",
    "        return (df.dropDuplicates()\n",
    "                  .na.drop(subset=pk_cols)\n",
    "        )\n",
    "\n",
    "    # SCD type 1 For dimension tables \n",
    "    def write_dim(self, df, table):\n",
    "        from delta import DeltaTable\n",
    "\n",
    "        tableName = table[:len(table) - 1]\n",
    "        pk = self.pk_dict[tableName]\n",
    "\n",
    "        if table in self.expectedDims:\n",
    "            print(f\"\\tAdding {tableName} to {self.silver_home}/{table}\")\n",
    "            silverDim = DeltaTable.forPath(spark, f\"{self.silver_home}/{table}\")\n",
    "            (silverDim.alias(\"tgt\")\n",
    "                    .merge(df.alias(\"src\"), f\"src.{pk} = tgt.{pk}\")\n",
    "                    .whenMatchedUpdateAll()\n",
    "                    .whenNotMatchedInsertAll()\n",
    "                    .execute()\n",
    "            )\n",
    "    \n",
    "    # Add All records, as long as no duplicates in silver table\n",
    "    def write_fact(self, df, table):\n",
    "        from delta import DeltaTable\n",
    "\n",
    "        tableName = table[:len(table) - 1]\n",
    "        pk_columns = self.pk_dict[tableName]\n",
    "        pk_columns_list = [col.strip() for col in pk_columns.split(\",\")]\n",
    "        pk_columns_list.append(\"loaded_ts\")\n",
    "        merge_condition = \" AND \".join([f\"src.{col} = tgt.{col}\" for col in pk_columns_list])\n",
    "        if table in self.expectedFacts:\n",
    "            print(f\"\\tAdding {tableName} to {self.silver_home}/{table}\")\n",
    "            silverFact = DeltaTable.forPath(spark, f\"{self.silver_home}/{table}\")\n",
    "            (silverFact.alias(\"tgt\")\n",
    "                    .merge(df.alias(\"src\"), merge_condition)\n",
    "                    .whenNotMatchedInsertAll()\n",
    "                    .execute()\n",
    "            )\n",
    "\n",
    "    def process(self):\n",
    "        bronzeList = self.get_table_list('bronze')\n",
    "        silverList = self.get_table_list('silver')\n",
    "\n",
    "        for table in bronzeList:\n",
    "            if table in silverList and table in self.expectedDims:\n",
    "                print(f\"Dim table: {table}\")\n",
    "                bronzeDf = self.get_bz_table(table)\n",
    "                recentTs = self.get_recent_ts(table)\n",
    "                # get the most recent loaded_ts from bronze\n",
    "                filteredBronzeDf = self.filter_bz_table(bronzeDf, recentTs)\n",
    "                cleanedFilteredDf = self.clean_df(filteredBronzeDf, table)\n",
    "                self.write_dim(cleanedFilteredDf, table)\n",
    "            \n",
    "            elif table in silverList and table in self.expectedFacts:\n",
    "                print(f\"Fact table: {table}\")\n",
    "                bronzeDf = self.get_bz_table(table)\n",
    "                recentTs = self.get_recent_ts(table)\n",
    "                # get the most recent loaded_ts from bronze\n",
    "                filteredBronzeDf = self.filter_bz_table(bronzeDf, recentTs)\n",
    "                cleanedFilteredDf = self.clean_df(filteredBronzeDf, table)\n",
    "                self.write_fact(cleanedFilteredDf, table)\n",
    "\n",
    "            print(f\"Finished processing {table}. Added {filteredBronzeDf.count()} records!\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4222639-5449-4b2c-b7a1-15d5ab109230",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim table: channels/\n\tLoading Bronze Table at: abfss://bronze@datalakeselectivaproject.dfs.core.windows.net/channels/\n\tGetting most recent loaded_ts for: `selectiva-project`.edw.channels_edw\n\tFiltering Bronze Data on loaded_ts\n\tAdding channels to abfss://silver@datalakeselectivaproject.dfs.core.windows.net/edw/channels/\nFinished processing channels/. Added 0 records!\n\nFact table: costs/\n\tLoading Bronze Table at: abfss://bronze@datalakeselectivaproject.dfs.core.windows.net/costs/\n\tGetting most recent loaded_ts for: `selectiva-project`.edw.costs_edw\n\tFiltering Bronze Data on loaded_ts\n\tAdding costs to abfss://silver@datalakeselectivaproject.dfs.core.windows.net/edw/costs/\nFinished processing costs/. Added 0 records!\n\nDim table: customers/\n\tLoading Bronze Table at: abfss://bronze@datalakeselectivaproject.dfs.core.windows.net/customers/\n\tGetting most recent loaded_ts for: `selectiva-project`.edw.customers_edw\n\tFiltering Bronze Data on loaded_ts\n\tAdding customers to abfss://silver@datalakeselectivaproject.dfs.core.windows.net/edw/customers/\nFinished processing customers/. Added 0 records!\n\nDim table: products/\n\tLoading Bronze Table at: abfss://bronze@datalakeselectivaproject.dfs.core.windows.net/products/\n\tGetting most recent loaded_ts for: `selectiva-project`.edw.products_edw\n\tFiltering Bronze Data on loaded_ts\n\tAdding products to abfss://silver@datalakeselectivaproject.dfs.core.windows.net/edw/products/\nFinished processing products/. Added 0 records!\n\nDim table: promotions/\n\tLoading Bronze Table at: abfss://bronze@datalakeselectivaproject.dfs.core.windows.net/promotions/\n\tGetting most recent loaded_ts for: `selectiva-project`.edw.promotions_edw\n\tFiltering Bronze Data on loaded_ts\n\tAdding promotions to abfss://silver@datalakeselectivaproject.dfs.core.windows.net/edw/promotions/\nFinished processing promotions/. Added 0 records!\n\nFact table: sales/\n\tLoading Bronze Table at: abfss://bronze@datalakeselectivaproject.dfs.core.windows.net/sales/\n\tGetting most recent loaded_ts for: `selectiva-project`.edw.sales_edw\n\tFiltering Bronze Data on loaded_ts\n\tAdding sales to abfss://silver@datalakeselectivaproject.dfs.core.windows.net/edw/sales/\nFinished processing sales/. Added 0 records!\n\nDim table: supplementary_demographics/\n\tLoading Bronze Table at: abfss://bronze@datalakeselectivaproject.dfs.core.windows.net/supplementary_demographics/\n\tGetting most recent loaded_ts for: `selectiva-project`.edw.supplementary_demographics_edw\n\tFiltering Bronze Data on loaded_ts\n\tAdding supplementary_demographics to abfss://silver@datalakeselectivaproject.dfs.core.windows.net/edw/supplementary_demographics/\nFinished processing supplementary_demographics/. Added 0 records!\n\nDim table: times/\n\tLoading Bronze Table at: abfss://bronze@datalakeselectivaproject.dfs.core.windows.net/times/\n\tGetting most recent loaded_ts for: `selectiva-project`.edw.times_edw\n\tFiltering Bronze Data on loaded_ts\n\tAdding times to abfss://silver@datalakeselectivaproject.dfs.core.windows.net/edw/times/\nFinished processing times/. Added 0 records!\n\n"
     ]
    }
   ],
   "source": [
    "s = silver()\n",
    "s.process()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4996753451729180,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01-transform",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}